{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOgz1GIa5LMc1WR/wzbbp/8",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Gunasheela-KS/NLP/blob/main/Document_QA_Langchain_GPT.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# !pip install --upgrade langchain openai -q\n",
        "# !pip install unstructured -q\n",
        "# !pip install unstructured[local-inference] -q\n",
        "# !pip install detectron2@git+https://github.com/facebookresearch/detectron2.git@v0.6\n",
        "# !apt-get install poppler-utils\n",
        "# !pip install tiktoken -q\n",
        "# !pip install pinecone-client -q\n",
        "# !pip install --upgrade PIL\n",
        "import os\n",
        "import openai\n",
        "import pinecone\n",
        "import PIL\n",
        "from PIL import Image\n",
        "from langchain.document_loaders import DirectoryLoader\n",
        "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
        "from langchain.embeddings.openai import OpenAIEmbeddings\n",
        "from langchain.vectorstores import Pinecone\n",
        "from langchain.llms import OpenAI\n",
        "from langchain.chains.question_answering import load_qa_chain"
      ],
      "metadata": {
        "id": "MoDTCRrserwz"
      },
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "os.environ['OPENAI_API_KEY']='your_key'"
      ],
      "metadata": {
        "id": "2v3SwWZwKwio"
      },
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "directory = '/content/data'\n",
        "\n",
        "def load_docs(directory):\n",
        "  loader = DirectoryLoader(directory)\n",
        "  documents = loader.load()\n",
        "  return documents\n",
        "\n",
        "documents = load_docs(directory)\n",
        "len(documents)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LC7TRaQCFboQ",
        "outputId": "36883b3e-2a66-40d7-fbb3-964b7e233283"
      },
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2"
            ]
          },
          "metadata": {},
          "execution_count": 49
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def split_docs(documents, chunk_size=1000, chunk_overlap=20):\n",
        "  text_splitter = RecursiveCharacterTextSplitter(chunk_size=chunk_size, chunk_overlap=chunk_overlap)\n",
        "  docs = text_splitter.split_documents(documents)\n",
        "  return docs\n",
        "\n",
        "docs = split_docs(documents)\n",
        "print(len(docs))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tmGtvRu9JqbW",
        "outputId": "7da87744-bb63-4fe3-d289-4efae7874812"
      },
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "4\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "embeddings = OpenAIEmbeddings(model=\"ada\")"
      ],
      "metadata": {
        "id": "a98E11QsKZsD"
      },
      "execution_count": 51,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pinecone.init(\n",
        "    api_key=\"your_pinecone_api_key\",\n",
        "    environment=\"your_env\"\n",
        ")\n",
        "index_name = \"langchain-demo\""
      ],
      "metadata": {
        "id": "hsmeUV4RKkMt"
      },
      "execution_count": 52,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pinecone.create_index(index_name, dimension=1536,\n",
        "                          metric=\"cosine\", pods=1, pod_type=\"p1.x1\")"
      ],
      "metadata": {
        "id": "7puNeq4LZdbP"
      },
      "execution_count": 53,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "index = Pinecone.from_documents(docs, embeddings, index_name=index_name)"
      ],
      "metadata": {
        "id": "p92ySFm8Xx-_"
      },
      "execution_count": 54,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_similiar_docs(query, k=2, score=False):\n",
        "  if score:\n",
        "    similar_docs = index.similarity_search_with_score(query, k=k)\n",
        "  else:\n",
        "    similar_docs = index.similarity_search(query, k=k)\n",
        "  return similar_docs\n",
        "\n",
        "def get_answer(query):\n",
        "  similar_docs = get_similiar_docs(query)\n",
        "  answer = chain.run(input_documents=similar_docs, question=query)\n",
        "  return answer"
      ],
      "metadata": {
        "id": "DWTa8yrIL66E"
      },
      "execution_count": 56,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# model_name = \"text-davinci-003\"\n",
        "# model_name = \"gpt-3.5-turbo\"\n",
        "model_name = \"gpt-3.5-turbo\"\n",
        "llm = OpenAI(model_name=model_name)\n",
        "\n",
        "chain = load_qa_chain(llm, chain_type=\"stuff\")"
      ],
      "metadata": {
        "id": "_McqksktL6_w"
      },
      "execution_count": 58,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "query = \"What is pinecone?\"\n",
        "answer = get_answer(query)\n",
        "print(answer)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wyo71wl0MCwB",
        "outputId": "9b19852e-8bc4-4b51-9876-eb9cc942e475"
      },
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Pinecone is an indexing and similarity search system developed by OpenAI that provides a vector database for storing and retrieving vectors based on their similarity, particularly well-suited for applications such as recommendation systems, natural language processing, and computer vision. It leverages advanced algorithms and data structures, such as approximate nearest neighbor (ANN) search, and provides a simple API for easy integration into applications. By using Pinecone, developers can create highly performant and accurate recommendation systems, personalized search engines, content matching systems, and more.\n"
          ]
        }
      ]
    }
  ]
}